---
layout: post
title: "celery 笔记\_"
tagline: 架构
category: null
tags: []
published: true

---
## 架构 笔记##

##网络通信协议 ##
诸如TCP/UDP等等）、网络IO（Blocking-IO，NonBlocking-IO、Asyn-IO）、网卡（多队列等）；更偏应用的层面，需要了解例如连接复用、序列化/反序列化、RPC、负载均衡等

##支持大量连接、高并发、低资源消耗的通信程序 ##
通信模式,中间件通讯模式,订阅等


1. 大量client连一个server
在现如今NonBlocking-IO这么成熟的情况下，一个支持大量client的server已经不那么难写了，但在大规模，并且通常长连接的情况下，有一个点要特别注意，就是当server挂掉的时候，不能出现所有client都在一个时间点发起重连，那样基本就是灾难，在没有经验的情况下我看过好几起类似的case，到client规模上去后，server一重启基本就直接被冲进来的大量建连冲垮了（当然，server的backlog队列首先应该稍微设置大一些），通常可以采用的方法是client重连前都做随机时间的sleep，另外就是重连的间隔采取避让算法。

2. 一个client连大量的server
有些场景也会出现需要连大量server的现象，在这种情况下，同样要注意的也是不要并发同时去建所有的连接，而是在能力范围内分批去建。
除了建连接外，另外还要注意的地方是并发发送请求也同样，一定要做好限流，否则很容易会因为一些点慢导致内存爆掉。

##高并发##
高并发这个点需要掌握CAS、常见的lock-free算法、读写锁、线程相关知识（例如线程交互、线程池）等，通信层面的高并发在NonBlocking-IO的情况下，最重要的是要注意在整体设计和代码实现上尽量减少对io线程池的时间占用。

###Nginx ###
![nginx](http://www.rowkey.me/images/blog_images/nginx/ngx_arch.jpg)
* 一个 master 进程负责分配工作,master进程主要用来管理worker进程


worker进程则是处理基本的网络事件。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。

开发模型：epoll和kqueue。

支持的事件机制：kqueue、epoll、rt signals、/dev/poll 、event ports、select以及poll。

1.1 负载均衡

* 加权均衡
![weight](http://www.rowkey.me/images/blog_images/nginx/ngx_wr.png)
排序 -> 链接 -> 减重 ->排序


* iphash

'''
 for(i = 0;i < 3;i++){
     hash = (hash * 113 + iphp->addr[i]) % 6271; 
 }

 p = hash % iphp->rrp.peers->number; 
'''

hash 值与 ip 和后端机器数量有关,最大1045个值.当经过20次hash仍然找不到可用的机器时，算法退化成轮询。如果两个ip的初始hash值恰好相同，那么来自这两个ip的请求将永远落在同一台服务器上，这为均衡性埋下了很深的隐患。

* fair

是根据后端服务器的响应时间判断负载情况，从中选出负载最轻的机器进行分流.

* 通用hash、一致性hash


* session_sticky
一次会话内的请求都会落到同一个结点上

1.2 动态负载均衡

1.2.1 自身监控


内置了对后端服务器的健康检查功能。如果Nginx proxy后端的某台服务器宕机了，会把返回错误的请求重新提交到另一个节点，不会影响前端访问。它没有独立的健康检查模块，而是使用业务请求作为健康检查，这省去了独立健康检查线程，这是好处。坏处是，当业务复杂时，可能出现误判，例如后端响应超时，这可能是后端宕机，也可能是某个业务请求自身出现问题，跟后端无关。




