---
layout: post
title: "celery 笔记\_"
tagline: 架构
category: null
tags: []
published: true

---
## 架构 笔记##

##网络通信协议 ##
诸如TCP/UDP等等）、网络IO（Blocking-IO，NonBlocking-IO、Asyn-IO）、网卡（多队列等）；更偏应用的层面，需要了解例如连接复用、序列化/反序列化、RPC、负载均衡等

##支持大量连接、高并发、低资源消耗的通信程序 ##
通信模式,中间件通讯模式,订阅等


1. 大量client连一个server
在现如今NonBlocking-IO这么成熟的情况下，一个支持大量client的server已经不那么难写了，但在大规模，并且通常长连接的情况下，有一个点要特别注意，就是当server挂掉的时候，不能出现所有client都在一个时间点发起重连，那样基本就是灾难，在没有经验的情况下我看过好几起类似的case，到client规模上去后，server一重启基本就直接被冲进来的大量建连冲垮了（当然，server的backlog队列首先应该稍微设置大一些），通常可以采用的方法是client重连前都做随机时间的sleep，另外就是重连的间隔采取避让算法。

2. 一个client连大量的server
有些场景也会出现需要连大量server的现象，在这种情况下，同样要注意的也是不要并发同时去建所有的连接，而是在能力范围内分批去建。
除了建连接外，另外还要注意的地方是并发发送请求也同样，一定要做好限流，否则很容易会因为一些点慢导致内存爆掉。

##高并发##
高并发这个点需要掌握CAS、常见的lock-free算法、读写锁、线程相关知识（例如线程交互、线程池）等，通信层面的高并发在NonBlocking-IO的情况下，最重要的是要注意在整体设计和代码实现上尽量减少对io线程池的时间占用。

##伸缩性##

分布式系统基本就意味着规模不小了，对于这类系统在设计的时候必须考虑伸缩性问题，架构图上画的任何一个点，如果请求量或者是数据量不断增大，怎么做到可以通过加机器的方式来解决，当然，这个过程也不用考虑无限大的场景，如果经历过从比较小到非常大规模的架构师，显然优势是不小的，同样也会是越来越稀缺的。

1. 无状态场景
对于无状态场景，要实现随量增长而加机器支撑会比较简单，这种情况下只用解决节点发现的问题，通常只要基于负载均衡就可以搞定，硬件或软件方式都有；
无状态场景通常会把很多状态放在db，当量到一定阶段后会需要引入服务化，去缓解对db连接数太多的情况。
2. 有状态场景
所谓状态其实就是数据，通常采用Sharding来实现伸缩性，Sharding有多种的实现方式，常见的有这么一些：
2.1 规则Sharding
基于一定规则把状态数据进行Sharding，例如分库分表很多时候采用的就是这样的，这种方式支持了伸缩性，但通常也带来了很复杂的管理、状态数据搬迁，甚至业务功能很难实现的问题，例如全局join，跨表事务等。
2.2 一致性Hash
一致性Hash方案会使得加机器代价更低一些，另外就是压力可以更为均衡，例如分布式cache经常采用，和规则Sharding带来的问题基本一样。
2.3 Auto Sharding
Auto Sharding的好处是基本上不用管数据搬迁，而且随着量上涨加机器就OK，但通常Auto Sharding的情况下对如何使用会有比较高的要求，而这个通常也就会造成一些限制，这种方案例如HBase。
2.4 Copy
Copy这种常见于读远多于写的情况，实现起来又会有最终一致的方案和全局一致的方案，最终一致的多数可通过消息机制等，全局一致的例如zookeeper/etcd之类的，既要全局一致又要做到很高的写支撑能力就很难实现了。

##稳定性##
作为分布式系统，必须要考虑清楚整个系统中任何一个点挂掉应该怎么处理（到了一定机器规模，每天挂掉一些机器很正常），同样主要还是分成了无状态和有状态：
1. 无状态场景
对于无状态场景，通常好办，只用节点发现的机制上具备心跳等检测机制就OK，经验上来说无非就是纯粹靠4层的检测对业务不太够，通常得做成7层的，当然，做成7层的就得处理好规模大了后的问题。
2. 有状态场景
对于有状态场景，就比较麻烦了，对数据一致性要求不高的还OK，主备类型的方案基本也可以用，当然，主备方案要做的很好也非常不容易，有各种各样的方案，对于主备方案又觉得不太爽的情况下，例如HBase这样的，就意味着挂掉一台，另外一台接管的话是需要一定时间的，这个对可用性还是有一定影响的；
全局一致类型的场景中，如果一台挂了，就通常意味着得有选举机制来决定其他机器哪台成为主，常见的例如基于paxos的实现。

##可维护性##
维护性是很容易被遗漏的部分，但对分布式系统来说其实是很重要的部分，例如整个系统环境应该怎么搭建，部署，配套的维护工具、监控点、报警点、问题定位、问题处理策略等等。


### 缓存 ###
1 动静分离
- 静态页面缓存在客户端,刷新到 cdn
- 动态数据分层效验,前端分流效验数据时候能够走 cache, 后端限流写数据任务
- 数据库层需要做强一致性效验

2 优化
- 建立实时热点分析系统,实时推送热点到 cache
- 请求在代理层上直接返回,不要下放到应用层.应用层只处理动态数据.

3 大并发
- 并发数据,包括动态静态全部进缓存
- 应用层对队列进行排序,避免同一资源请求占用太多连接
- 数据库层进行事务排队

###负载均衡###

####IP####

在网络层通过修改请求目标地址进行负载均衡。 用户请求数据包，到达负载均衡服务器后，负载均衡服务器在操作系统内核进程获取网络数据包，根据负载均衡算法得到一台真实服务器地址，然后将请求目的地址修改为，获得的真实ip地址，不需要经过用户进程处理。 真实服务器处理完成后，响应数据包回到负载均衡服务器，负载均衡服务器，再将数据包源地址修改为自身的ip地址，发送给用户浏览器。



####链路层####

在通信协议的数据链路层修改mac地址，进行负载均衡。 数据分发时，不修改ip地址，指修改目标mac地址，配置真实物理服务器集群所有机器虚拟ip和负载均衡服务器ip地址一致，达到不修改数据包的源地址和目标地址，进行数据分发的目的。 实际处理服务器ip和数据请求目的ip一致，不需要经过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。也称为直接路由模式（DR模式）。

####混合####　　

其实这就显而易见了，当单一的负载均衡方式无法很好的解决现有的问题，那么我们就可以把他们结合在一起使用，这也很符合当下的发展潮流啊… 具体的结合方式有很多，例如　我们可以考虑分层，在每一层采用不同的方式来进行负载均衡，在最外层使用 DNS负载均衡，在使用反向代理来做缓存以及动态请求分发 ，最后在是应用负载均衡(IP/DR), 分流到对应的应用集群　
![dr1](http://7xnp02.com1.z0.glb.clouddn.com/820332-20151213200106747-94797427.png)
![dr2](http://7xnp02.com1.z0.glb.clouddn.com/820332-20151213200117825-1452672107.png)


####LVS####

抗负载能力强，因为lvs工作方式的逻辑是非常之简单，而且工作在网络4层仅做请求分发之用，没有流量，所以在效率上基本不需要太过考虑。
配置性低，这通常是一大劣势，但同时也是一大优势，因为没有太多可配置的选项，所以除了增减服务器，并不需要经常去触碰它，大大减少了人为出错的几率。
工作稳定，因为其本身抗负载能力很强，所以稳定性高也是顺理成章，另外各种lvs都有完整的双机热备方案，所以一点不用担心均衡器本身会出什么问题，节点出现故障的话，lvs会自动判别，所以系统整体是非常稳定的。
无流量，上面已经有所提及了。lvs仅仅分发请求，而流量并不从它本身出去，所以可以利用它这点来做一些线路分流之用。没有流量同时也保住了均衡器的IO性能不会受到大流量的影响。
基本上能支持所有应用，因为lvs工作在4层，所以它可以对几乎所有应用做负载均衡，包括http、数据库、聊天室等等.

####ngingx haproxy ####

　
HaProxy

HAProxy是工作在网络7层之上。
能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作
支持url检测后端的服务器出问题的检测会有很好的帮助。
更多的负载均衡策略比如：动态加权轮循(Dynamic Round Robin)，加权源地址哈希(Weighted Source Hash)，加权URL哈希和加权参数哈希(Weighted Parameter Hash)已经实现
单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度。
HAProxy可以对Mysql进行负载均衡，对后端的DB节点进行检测和负载均衡。
Nignx

工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构；
Nginx对网络的依赖比较小；
Nginx安装和配置比较简单，测试起来比较方便；
也可以承担高的负载压力且稳定，一般能支撑超过1万次的并发；
Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测；
Nginx对请求的异步处理可以帮助节点服务器减轻负载；
Nginx能支持http和Email，这样就在适用范围上面小很多；
不支持Session的保持、对Big request header的支持不是很好，另外默认的只有Round-robin和IP-hash两种负载均衡算法。

###负载均衡算法 ###

随机
请求随机分配到各个服务器。

轮询
将所有请求，依次分发到每台服务器上，适合服务器硬件同相同的场景。

最少连接
优先将请求发给拥有最少连接数的后端服务器，常用于长连接服务，例如数据库连接等服务。

源地址
将请求的源地址进行hash运算，并结合后端的服务器的权重派发请求至某匹配的服务器，这可以使得同一个客户端IP的请求始终被派发至某特定的服务器。该方式适合负载均衡无cookie功能的TCP协议。

加权　　
在轮询，随机，最少链接，Hash’等算法的基础上，通过加权的方式，进行负载服务器分配。　　


###Nginx ###
![nginx](http://www.rowkey.me/images/blog_images/nginx/ngx_arch.jpg)
* 一个 master 进程负责分配工作,master进程主要用来管理worker进程


worker进程则是处理基本的网络事件。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。

开发模型：epoll和kqueue。

支持的事件机制：kqueue、epoll、rt signals、/dev/poll 、event ports、select以及poll。

1.1 负载均衡

* 加权均衡
![weight](http://www.rowkey.me/images/blog_images/nginx/ngx_wr.png)
排序 -> 链接 -> 减重 ->排序


* iphash

'''
 for(i = 0;i < 3;i++){
     hash = (hash * 113 + iphp->addr[i]) % 6271; 
 }

 p = hash % iphp->rrp.peers->number; 
'''

hash 值与 ip 和后端机器数量有关,最大1045个值.当经过20次hash仍然找不到可用的机器时，算法退化成轮询。如果两个ip的初始hash值恰好相同，那么来自这两个ip的请求将永远落在同一台服务器上，这为均衡性埋下了很深的隐患。

* fair

是根据后端服务器的响应时间判断负载情况，从中选出负载最轻的机器进行分流.

* 通用hash、一致性hash


* session_sticky
一次会话内的请求都会落到同一个结点上

1.2 动态负载均衡

1.2.1 自身监控


内置了对后端服务器的健康检查功能。如果Nginx proxy后端的某台服务器宕机了，会把返回错误的请求重新提交到另一个节点，不会影响前端访问。它没有独立的健康检查模块，而是使用业务请求作为健康检查，这省去了独立健康检查线程，这是好处。坏处是，当业务复杂时，可能出现误判，例如后端响应超时，这可能是后端宕机，也可能是某个业务请求自身出现问题，跟后端无关。
####location####
location 指令接受两种类型的参数：

前缀字符串（路径名称）
正则表达式
对于前缀字符串参数， URIs 必须严格的以它开头。例如对于 /some/path/ 参数，可以匹配 /some/path/document.html ，但是不匹配 /my-site/some/path，因为 /my-site/some/path 不以 /some/path/ 开头。

location /some/path/ {
    ...
}
对于正则表达式，以 ~ 开头表示大小写敏感，以 ~* 开头表示大小写不敏感。注意路径中的 . 要写成 \. 。例如一个匹配以 .html 或者 .htm 结尾的 URI 的 location：

location ~ \.html? {
    ...
}
正则表达式的优先级大于前缀字符串。如果找到匹配的前缀字符串，仍继续搜索正则表达式，但如果前缀字符串以 ^~ 开头，则不再检查正则表达式。

具体的搜索匹配流程如下：

将 URI 与所有的前缀字符串进行比较。
= 修饰符表明 URI 必须与前缀字符串相等（不是开始，而是相等），如果找到，则搜索停止。
如果找到的最长前缀匹配字符串以 ^~ 开头，则不再搜索正则表达式是否匹配。
存储匹配的最长前缀字符串。
测试对比 URI 与正则表达式。
找到第一个匹配的正则表达式后停止。
如果没有正则表达式匹配，使用 4 存储的前缀字符串对应的 location。
= 修饰符拥有最高的优先级。如网站首页访问频繁，我们可以专门定义一个 location 来减少搜索匹配次数（因为搜索到 = 修饰的匹配的 location 将停止搜索），提高速度：

location = / {
    ...
}
####nginx 附录 ####
常用正则
. ： 匹配除换行符以外的任意字符
? ： 重复0次或1次
+ ： 重复1次或更多次
*： 重复0次或更多次
\d ：匹配数字
^ ： 匹配字符串的开始
$ ： 匹配字符串的介绍
{n} ： 重复n次
{n,} ： 重复n次或更多次
[c] ： 匹配单个字符c
[a-z]： 匹配a-z小写字母的任意一个
全局变量
$args ： #这个变量等于请求行中的参数，同$query_string
$content_length ： 请求头中的Content-length字段。
$content_type ： 请求头中的Content-Type字段。
$document_root ： 当前请求在root指令中指定的值。
$host ： 请求主机头字段，否则为服务器名称。
$http_user_agent ： 客户端agent信息
$http_cookie ： 客户端cookie信息
$limit_rate ： 这个变量可以限制连接速率。
$request_method ： 客户端请求的动作，通常为GET或POST。
$remote_addr ： 客户端的IP地址。
$remote_port ： 客户端的端口。
$remote_user ： 已经经过Auth Basic Module验证的用户名。
$request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。
$scheme ： HTTP方法（如http，https）。
$server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。
$server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。
$server_name ： 服务器名称。
$server_port ： 请求到达服务器的端口号。
$request_uri ： 包含请求参数的原始URI，不包含主机名，如：/foo/bar.php?arg=baz。
$uri ： 不带请求参数的当前URI，$uri不包含主机名，如/foo/bar.html。
$document_uri ： 与$uri相同。
例如请求：http://localhost:88/test1/test2/test.php
$host：localhost
$server_port：88
$request_uri：http://localhost:88/test1/test2/test.php
$document_uri：/test1/test2/test.php
$document_root：/var/www/html
$request_filename：/var/www/html/test1/test2/test.php

## 持续集成 ##


开发者更新工作区
Jenkins收到通知
Jenkins克隆工作区
Jenkins创建一个Docker镜像
Jenkins运行测试
Jenkins将镜像推到Docker Hub


## 一致性哈希## 
* 传统哈希算话可能会导致大量的数据迁移开销

* 在consistent hash中，有一个hash环，代表一个范围，例如，可以取值为[0,2^64-1]。对于，每个Cache Server会根据hash函数算出一个整数值，最终落到hash环的某个点上，如图中的Cache Server 1-5。每个(key,value)对存储在hash环上顺时针的下一个Cache Server，举个例子，假设hash(Cache Server i) = Hi，i=1..5，如果(1,2)的hash取值处于[H1,H2)之间的话，那么它会存储在Cache Server2上，以此类推。

'''
Cache Server在hash环上的分布可能不均匀，导致Cache Server间的负载不均衡
Cache Server的配置可能不同，所以能承受的负载也不同，而上述的consistent hash是没有考虑这个因素的
'''


##MESOS##


###Mesos内部构成###
首先，Mesos是一个分布式的架构，它分Mesos master和Mesos slave，slave和master分别有不同的职责。从Mesos的源代码可以看出Mesos实现得比较优雅——它是一个C++代码。代码中有大量的关键词叫process，它不是传统意义上的进程，而是一种抽象的libprocess，libprocess是它最核心的库。如果大家以前使用过Erlang的语言就知道libprocess实际是对Erlang的IO和通讯模型的一个抽象。

libprocess，在Erlang里面也叫进程，实际上是一个虚拟进程，在运行Erlang的VM上。它最优的特点是消息在不同的process之间传递，它抽象了process，消息传递其实是一个事件的库。向process里发一个消息，这个消息不是直接打到process，而是中间有一个buffer的过程。

这样做的优点是特别适合分布式的系统，以前最常用的做法是监听网络端口，有包来了，有一个模块专门负责解这个包，解开一个协议后把这个协议发到后面一个处理进程，这个处理的进程可能是IO操作，可能去做其它事情，然后里面有很多IO上的Block，最后构造出一个response，通过一个socket传给客户端。这是最常用的一个写网络程序的办法，但是这里有一个大的IO上Block的地方——后面处理的逻辑依赖于解包的逻辑。如果处理逻辑很快，但解包逻辑很慢，后面会拖慢，都在等解包。

后来人们想到一种IO处理的方式，让任何一个东西都是分离的，比如从某一个端口收到一个消息，有一个单独的进程，一个线程或者其它的东西去处理这个唯一的请求。这个线程很重，后来大家又发明了一些其它的东西，比如golang里面去搞一个channel，Erlang里面去搞一个process。libprocess实际上做了IO方面的事情， Mesos大量使用这个模型。
   
Zookeeper
Mesos底层实际上依赖于Zookeeper，为了保证分布式存储最终一致性。在Mesos运行过程中产生了一些数据，最终都会落在Zookeeper。因为Mesos是多个master，为了达到HA的需求，只要一个master活的，那么整个服务就能得到保证。
   
protobuf
Mesos内部在通信里面选择了protobuf协议。好处是比较流行，各个语言的库都比较多，结构化的语义也比较强，所以Mesos内部选择了protobuf。
 
###Mesos概念解析### 


Mesos master&slave   
Mesos是一个分布式的系统，分master和slave， master的部分主要协调任务的分发、一些资源的调度。slave是负责执行的部分，比如一个任务最终是slave去执行的。当然，可以配在master执行。Mesos是一个双层调度，slave处于下层，也就是说可以动态的增加或者减少一些slave而不影响整个的任务池资源的变化，不影响上一层的任务。
  
Executor
Executor是真正的执行任务的逻辑。Mesos平台不太区分需要执行什么任务，所以它给用户一些灵活性，可以写不同的Executor。比如最常用的Mesos运行容器的部分，就是一个Executor。还有Map Reduce的大型任务，一个Map、一个Reduce， Executor都可以执行。它的表现形式可以是一个二进制，Mesos在运行时，slave会把Executor从远程一个URL上拉下来，然后开始执行Executor。
   
Scheduler
Scheduler的意思是调度， Mesos master和slave把资源收上来之后，再把这些任务交给Scheduler，由Scheduler决定应该运行什么Task。
   
Framework
Framework是双层调度的上一层，也就是由Framework来决定到底该执行什么任务，然后执行多少这样的任务。
   
Offer
Offer是Mesos资源的抽象，比如说有多少CPU、多少memory，disc是多少，都放在Offer里，打包给一个Framework，然后Framework来决定到底怎么用这个Offer。
  
Task
Task实际上是运行的小任务。有两大类Task，一大类我们叫Long Running Task，比如Docker的一个进程或者其它的进程。另外一类是Batch类型任务，这类应用非常广泛，比如说Map Reduce这么一个小任务或者是定时任务。

###Mesos内部工作原理###



Mesos master & slave
Mesos master是整个集群的核心，master为了保证高可用其实是可以跑多个master，分布式系统为了保证尽量的高可用，其实是可以有多个master在那儿运行的。比如倒了几个master，不会影响整个服务。Mesos master主要内部的工作有：Framework注册或者Framework出了什么问题，它来保证Framework的生命周期；slave的添加、slave的异常、slave的任务分配，我把它叫做slave的Lifecycle；Task Management，比如说Mesos master可能记录了哪些Task运行在哪些slave上；Resource Allocation&Offer，就是说slave有什么资源汇报给master，然后由master把这些任务交给注册在这个master上的一些Framework。
   
slave可以动态添加和减少，它lost不会影响整个服务，只是把这个事件（比如说一个slave掉了）由master去通知Framework。在Mesos slave代码里有大量执行器，即Executor的逻辑，因为所有Executor都是在slave上执行的，包括把Executor从远程拉下来、开始执行Executor、开始执行launch task，维护task的生命周期，task fail了如何去做等等。

Mesos Framework
Mesos的定位是一些资源的调度，它把任务的调度交给了Framework来做，Mesos只关心资源以及把资源给了谁， Framework来决定哪些资源怎么去使用。Mesos鼓励Framework在上面共生。想象一下，作为一个大型公司，有很多的资源，有核心的一组人来维护Mesos的集群，不断的往Mesos上添加资源和减少资源，而把Framework执行的能力交给其它的组、需要资源的那些组，各个组就可以写自己的Framework，丢到整个大的Mesos集群上来执行了。Mesos框架上和执行上各种各样的Framework，而Mesos本身也不了解为什么Framework工作，它只是知道把Offer给Framework，然后Framework告诉它来执行什么样的Executor。
   
两个比较流行的Framework
Marathon Framework，它的任务偏Long Running，核心是application。因为Mesos只关注task本身，task偏向于小任务，不会产生什么巨大的效应，而在企业里面尤其是弹性应用，更多是一个应用，它有很多的实例来执行，这就是Marathon来做的。
  
Chornous是一个偏Job、定时任务类型，如果把定时任务以Docker形式发出来，这个Chornous是非常适合的。传统的的Cron Job也是解决这类问题， Cron Job其实有很大的痛点，因为Cron Job是跑在主机上的，主机有limit的限制，如何把Cron Job放在多机上，需要有一个很好的哈希算法。到底如何把一堆单台机器很难执行的多个job水平分布在很多机器上，很麻烦。但是有了这个Chornous的Framework，事情就变得简单多了。
   
Scheduler/Scheduler Driver
它们俩区分度不是太大，有一些区分。Scheduler是做任务分配的，它从master上得到一个Offer的事件，拿到Offer后，决定到底接受这个Offer还是拒绝，接受这个Offer之后，把什么样的Task放在这个Offer上， Framework也开始占用这个Offer，这是Scheduler做的事情。Scheduler Driver其实是偏消息通信的那一部分，而Scheduler可定制化特别强，在代码里看到Scheduler其实是一个java的abstract glass，相当于一个interface，Framework自己去实现这么一个东西。如果想写一个Framework，其实大部分时间在如何写好一个Scheduler实现这一部分。
   
Executor/Executor Driver
如果Executor和Scheduler是对应的， Executor就是执行的这一部分。Mesos container这个Executor是Mesos自己提供的，不用写Executor就可以launch一个Docker的任务。但如果有一些自己的需求，就需要去实现一个Executor，比如七牛和乐视实现了一些Executor。



###Marathon###


刚才已经提到了Marathon基本的功能，Marathon作为一个Long Running上一层的调度机制，为用户做了很多有意义的事情。单纯一个Mesos的话做不了什么，因为Task的力度特别小，Mesos的功能更偏重于资源的管理、资源的调度，Marathon更偏向于一些任务。

Marathon提出了几个概念，最核心的概念叫application，还有Group的application，是一组的application。一个application是什么呢？比如一个Rails的任务、NodeJS任务或者其它的一些任务，在部署的时候并不是部署一个Task，而是部署非常多的Task，application就是一组Task。这个Task在Marathon里面叫instance，可以选择scale down或者scale up这些instance，这些任务最终交给Mesos，Mesos调度到不同的slave上。

围绕着这个application，Marathon就提供了一些概念叫Group，Group是一组application。举例来说，在内部可能有很多的微服务，这些微服务达到同一个目标，比如说服务之间还有调用、还有依赖，这时去发一个Group application就比较好用。但实际工作中，因为生产级别的服务对稳定性的要求很高， Group之间其实假设服务和服务之间是有一定的依赖。
  
Marathon提供了一个有意思的feature—— rolling update。假如有APP的新版本上来，它可以通过一定的机制去发多个版本，而且可以多个版本共存。如果那个新版本没有问题的话，可以继续preceeding deployment。如果有问题的话，可以Rollback。这时有两个概念Deployment和Version，可以选定哪一个Version，想Rollback哪个Version。Deployment是每次update，每次更新、每次重新的Deployment、每次scale，都会在内部生成一个Deployment，和应用一对多有关。有趣的是Deployment之间是不可以重叠的，Deployment是一种部署排队的机制，Deployment不可以多个同时进行，既想update又想scale，会让Marathon崩溃。
  
Marathon scale和rolling update的功能都非常有用，比如新浪微博现在有一个大的事件，需要更多的Task顶上来，立刻 scale up，只要资源足够就可以无限多的Task生成。Rollback，如果有一个版本有问题，可以瞬间Rollback到以前一个健康的版本。
  
虽然Mesos对下面的资源做了一些抽象，但是有时候有一些倾向性，比如希望CPU使用率比较高的一些任务调度到CPU比较好的机器上，需要一种在调度上的倾向性来满足刚才的场景。很多调度器都有类似的功能，叫Constraints，比如一台主机的label，要把Task打到一组主机这样的Label上或者是Host name like，这是Marathon做的，Mesos不用做这类的事情。
  
Marathon的接口非常友好，都是HTTP的接口。Mesos的接口by design不是面向最终用户，所以它的接口并不是那么友好。马拉松的UI也非常漂亮，尤其是新版

###Python###
学习Python的过程中，一开始我对于装饰器contextmanager+yield怎么都不懂。直到我看了contextmanager的源代码, 其实非常简单就懂了。它的docstring清楚地不能再清楚了：

https://hg.python.org/cpython/file/2.7/Lib/contextlib.py#l55

我之前使用多线程编程都这样用，在好长一段时间里面对于多进程和多线程之前怎么选择都搞得不清楚。看多了开源项目代码，我发现了好多人在用multiprocessing.dummy这个子模块，「dummy」这个词本身好奇怪，我决定去看多进程（multiprocessing）库的代码。「咦！怎么和多线程的接口一样呢」。后知后觉的我看到文档中这样说：

multiprocessing.dummy replicates the API of multiprocess
ing but is no more than a wrapper around the threading
module.

恍然大悟！！！如果分不清任务是CPU密集型还是IO密集型，我就用如下2个方法分别试：
from multiprocessing import Pool 
from multiprocessing.dummy import Pool
哪个速度快就用那个。从此以后我都尽量在写兼容的方式，这样在多线程/多进程之间切换非常方便。

13-14年间，Flask还没怎么火，那时候装饰器风格的Web框架还有一个Bottle。我当时就直接想去看Bottle代码，发现一上来import了一堆模块，你先感受下bottle/bottle.py at master · bottlepy/bottle · GitHub ，第一感觉就是懵啊，这都是干什么的啊，为什么要用啊？这就是促使我去看标准库实现最重要的原因：学会了我才能更好的看懂别人写的代码。

但是不是所有的标准库都要一视同仁的看呢？你可以设置优先级，先看那些不可不知道的模块。我在这里列一下，并对它的用途和其中重要的类、函数的作用加以说明等。要是每个都写例子实在太多太密集，怕大家看不下去，我都用外部链接了。

argparse。 用来替代optparse的命令行解析库。如果你考虑用更直观的，推荐docopt，它使用docstring所见即所得实现命令行解析。

collections。 包含了一些额外的数据类型。其中的OrderedDict（有序列的字典）、defaultdict（带有默认值的字典）、namedtuple（通过创建带有字段属性的元组子类）和deque（高效实现插入和删除操作的双向列表）非常常用。

functools。 这个模块有一些非常有用的工具，其中的partial（偏函数）、wraps（将被包装函数的信息拷贝过来）、totalordering（只需要定义2个_XX方法就可实现对象对比的类装饰器）、cmp_to_key（将老式的比较函数转化为关键字函数）非常常用。

glob。 文件名的shell模式匹配，你不用遍历整个目录判断每个文件是不是符合，使用glob一句话就解决。

multiprocessing。多进程模块，这重要性就不说了。

os。应该是日常工作最常用的模块了，你是否了解它里面所有的函数和实现呢？举个例子，获取环境变量，我之前这样用：

In : os.environ.get(‘PYTHONPATH’)
读完源码之后我学了一招：

os.getenv(‘PYTHONPATH’)
好吧，省了5个字符。

Queue。这个模块用于多线程编程，它是一个线程安全的FIFO（先进先出）的队列实现。如果是多进程编程，选用multiprocessing.queues中的Queue、SimpleQueue、JoinableQueue这三个队列实现。

SimpleHTTPServer。最简单地HTTP Server实现。不使用Web框架，一句：

python -m SimpleHTTPServer PORT
就可以运行起来静态服务。平时用它预览和下载文件太方便了。

subprocess。 如果你还被某些书籍引导使用os.system或者os.popen等模块，现在是放弃它们的时候了，这个模块会满足你绝大多数的系统命令执行、执行结果获取和解析等需求。其中最有用的是call（执行系统命令）、check_call（执行结果不为0则抛出异常）、check_output（最方便的获取执行的输出的函数）、Popen+PIPE（支持管道的多命令执行）。

threading。多线程模块，重要性也不必说。